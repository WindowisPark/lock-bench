# v2 실험 설계 템플릿 (판별 기준 포함)

작성일: 2026-02-19

## 목표
전략별 성능을 “현재 상태(베이스라인)”와 “최적화 상태(튜닝)”로 나눠 비교하고,
성공률/지연/처리량 기준으로 우위 판별 가능하게 만든다.

## 우선순위(서비스 관점)
1) 성공률/정확성  
2) 꼬리 지연(p95/p99)  
3) 처리량

## 실험 단계
### Phase A: 베이스라인(고정 설정)
- JVM, OS, HW, DB/Redis 설정 고정
- 동일 workload로 전략별 비교

### Phase B: 전략별 튜닝
- 각 전략에 대해 합리적인 튜닝(예: Redis TTL, 재시도)
- 동일 workload로 전략별 비교

## 고정 조건 체크리스트
- 하드웨어/OS 동일
- JVM 버전 동일, 힙 옵션 동일
- DB/Redis 버전 동일
- 네트워크 경로 동일
- 워밍업 후 측정 시작

## 워크로드 기준(권장)
- 조합당 반복: 10회(가능하면 20회)
- 실행 시간 기반: 30~60초
- 워밍업 1~2회 결과 제외
- 기록 지표: success/fail, p50/p95/p99, throughput

## 판별 기준(예시)
### 1) 성공률
- 실패율 1% 이상이면 우선 제외(락 기반 쓰기 기준)

### 2) 지연(p95/p99)
- 상대 비교: p95 혹은 p99가 10% 이상 개선되면 우위
- 절대 기준: p95 < 200ms (예시, 서비스 목표에 맞춰 조정)

### 3) 처리량
- 성공률/지연 기준 만족한 후보 중에서 처리량 비교
- 상대 개선 10% 이상이면 우위

## 결과 요약 포맷(권장)
| Strategy | Success Rate | p95 | p99 | Throughput | Verdict |
| --- | --- | --- | --- | --- | --- |

## 해석 가이드
- 실패율이 높으면 throughput이 높아도 “불리”로 판정
- p95/p99가 크게 나쁘면 사용자 체감 악화로 감점
- 튜닝 Phase는 “잠재력”, 베이스라인 Phase는 “현재 운영 적합성”
